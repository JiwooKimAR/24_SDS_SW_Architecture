{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Lab 3. Machine Learning - Linear and Logistic Regression, and Decision Tree\n",
        "\n",
        "## Table of Contents\n",
        "- Linear regression\n",
        "- Logistic regression\n",
        "- Decision Tree"
      ],
      "metadata": {
        "id": "9pEOVQePMPkj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download dataset"
      ],
      "metadata": {
        "id": "k8VXRdiGM-KO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "# happiness\n",
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1g-kEqWUe7zYGrxQ2tGTcuT5MN4XDCXFX' -O happiness_train.csv\n",
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1bFKKosFdHXGvU5lPIyjjnhv-aS5aPLj1' -O happiness_test.csv\n",
        "# iris\n",
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1vThUwXXgL_PtMpYq5PfVlygtLD46I6kA' -O Iris_Train.csv\n",
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1wdwS1iksXAkHlVa3aZwzpkYapATb5nZr' -O Iris_Test.csv\n",
        "# spam\n",
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=19KW6xooGxbUOq-f6C-5U3_0qhfmcY7zp' -O Spam_train.csv\n",
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1VyD2cL8GSyr8tkpWk8XsgbhpR-W10rpp' -O Spam_test.csv\n",
        "# titanic\n",
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1Afn3qiznaOEX437j5lEIV8SVmCwqy1Rl' -O Titanic_train.csv\n",
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1CgDkX3xT53xwxTeUOI6MT0YqO2L9mfV4' -O Titanic_test.csv"
      ],
      "metadata": {
        "id": "mnYfKNcPQNeo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import packages"
      ],
      "metadata": {
        "id": "Ea0Y6JuFNErD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import copy\n",
        "from os.path import join\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "np.random.seed(0)"
      ],
      "metadata": {
        "id": "FtQz1GYPMyWn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0p7ZixCu93-Z"
      },
      "source": [
        "# 1. Linear Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ubdhvk9U97af"
      },
      "source": [
        "## SKLearnì„ ì´ìš©í•œ Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VcoE64FB-pzS"
      },
      "outputs": [],
      "source": [
        "# ë°ì´í„° ì¤€ë¹„\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import make_regression\n",
        "\n",
        "X, y = make_regression(n_samples=100, n_features=1,\n",
        "                       bias=100, noise=40, random_state=1)\n",
        "\n",
        "\n",
        "# ë°ì´í„° ì‹œê°í™”\n",
        "plt.scatter(X, y, label=\"data\")\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5JrDghIv_xTI"
      },
      "outputs": [],
      "source": [
        "# biasë¥¼ í•œë²ˆì— ê³„ì‚°í•˜ê¸° ìœ„í•´, 1ì„ Xì— ì¶”ê°€í•´ ì¤ë‹ˆë‹¤.\n",
        "new_X = np.insert(X, 0, 1, axis=1)\n",
        "\n",
        "# train, test ë‚˜ëˆ”\n",
        "train_x, test_x, train_y, test_y = train_test_split(new_X, y, test_size=0.3, shuffle=True, random_state=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x7mBSxLf_agG"
      },
      "outputs": [],
      "source": [
        "# Scikit-Learn ìœ¼ë¡œ í•™ìŠµ\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "simple_linear = LinearRegression()\n",
        "simple_linear.fit(train_x, train_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "97R1qGz0Acph"
      },
      "outputs": [],
      "source": [
        "# train dataì— ëŒ€í•œ í•™ìŠµ ëª¨ë¸ ì‹œê°í™”\n",
        "plt.scatter(train_x[:,1], train_y, label=\"train data\")\n",
        "plt.plot(train_x[:,1], simple_linear.predict(train_x), 'r-', label=\"model\")\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5SmveKY8BnpE"
      },
      "outputs": [],
      "source": [
        "# test dataì— ëŒ€í•œ í•™ìŠµ ëª¨ë¸ ì‹œê°í™”\n",
        "plt.scatter(test_x[:,1], test_y, label=\"test data\")\n",
        "plt.plot(test_x[:,1], simple_linear.predict(test_x), 'r',  label=\"model\")\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o33OKDIX_kjH"
      },
      "outputs": [],
      "source": [
        "# í‰ê°€\n",
        "def RMSE(pred, target):\n",
        "  error = pred - target\n",
        "  square = error * error\n",
        "  mean = np.mean(square)\n",
        "  root = np.sqrt(mean)\n",
        "  return root\n",
        "\n",
        "pred = simple_linear.predict(train_x)\n",
        "print(\"Train RMSE =\", RMSE(pred, train_y))\n",
        "\n",
        "pred = simple_linear.predict(test_x)\n",
        "print(\"Test RMSE =\", RMSE(pred, test_y))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOXmn9BuQjXC"
      },
      "source": [
        "## Linear Regressionì˜ Numerical Solution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z21Sbgy2QjXC"
      },
      "outputs": [],
      "source": [
        "# ë°ì´í„° ì¤€ë¹„\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import make_regression\n",
        "\n",
        "X, y = make_regression(n_samples=100, n_features=1,\n",
        "                       bias=100, noise=40, random_state=1)\n",
        "\n",
        "\n",
        "# ë°ì´í„° ì‹œê°í™”\n",
        "plt.scatter(X, y, label=\"data\")\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tDW_fJnfQjXD"
      },
      "outputs": [],
      "source": [
        "# biasë¥¼ í•œë²ˆì— ê³„ì‚°í•˜ê¸° ìœ„í•´, 1ì„ Xì— ì¶”ê°€í•´ ì¤ë‹ˆë‹¤.\n",
        "new_X = np.insert(X, 0, 1, axis=1)\n",
        "\n",
        "# train, test ë‚˜ëˆ”\n",
        "train_x, test_x, train_y, test_y = train_test_split(new_X, y, test_size=0.3, shuffle=True, random_state=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CfuvYeagQ7Hd"
      },
      "outputs": [],
      "source": [
        "class LinearRegression_gd:\n",
        "    def __init__(self, num_features, seed):\n",
        "        np.random.seed(seed)\n",
        "        self.W = np.random.rand(num_features, 1)\n",
        "\n",
        "    def train(self, train_x, train_y, num_epochs, learning_rate):\n",
        "        num_data, num_features = train_x.shape\n",
        "\n",
        "        loss_memory = []\n",
        "        train_y = np.expand_dims(train_y, 1)\n",
        "\n",
        "        for i in range(num_epochs):\n",
        "\n",
        "            # prediction ê³„ì‚°\n",
        "            prediction = np.matmul(train_x, self.W)\n",
        "\n",
        "            # Error ë° Loss ê³„ì‚°\n",
        "            error = prediction - train_y\n",
        "            loss = np.mean(error * error) / 2\n",
        "\n",
        "            # Gradient ê³„ì‚°\n",
        "            gradient= np.mean(train_x * error, axis=0, keepdims=True).T # ğğ‘³(ğ’™, ğ‘¾)/ğğ‘¾\n",
        "\n",
        "            # Weight Update\n",
        "            # gradient, learning_rate í™œìš©í•˜ì—¬ self.W ì—…ë°ì´íŠ¸\n",
        "            self.W -= learning_rate * gradient\n",
        "\n",
        "            # Loss â€˜loss_memoryâ€™ì— ì¶”ê°€\n",
        "            loss_memory.append(loss)\n",
        "\n",
        "        # â€˜loss_memoryâ€™ ë°˜í™˜\n",
        "        return loss_memory\n",
        "\n",
        "    def predict(self, test_x):\n",
        "        pred = np.matmul(test_x, self.W).squeeze()\n",
        "        return pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "htEMq4AaQjXD"
      },
      "outputs": [],
      "source": [
        "# Hyper-parameter\n",
        "num_epochs = 1500\n",
        "learning_rate = 0.01\n",
        "seed = 15\n",
        "\n",
        "num_data, num_features = train_x.shape\n",
        "model = LinearRegression_gd(num_features, seed)\n",
        "loss_memory = model.train(train_x, train_y, num_epochs, learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oXxV3FF4UfJ-"
      },
      "outputs": [],
      "source": [
        "# Plot Loss\n",
        "x_axis = list(range(num_epochs))\n",
        "\n",
        "plt.plot(x_axis, loss_memory)\n",
        "plt.title('Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('MSE Loss')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SZmAouvrQjXD"
      },
      "outputs": [],
      "source": [
        "# train dataì— ëŒ€í•œ í•™ìŠµ ëª¨ë¸ ì‹œê°í™”\n",
        "plt.scatter(train_x[:,1], train_y, label=\"train data\")\n",
        "plt.plot(train_x[:,1], model.predict(train_x), 'r-', label=\"model\")\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PYFICMDzQjXD"
      },
      "outputs": [],
      "source": [
        "# test dataì— ëŒ€í•œ í•™ìŠµ ëª¨ë¸ ì‹œê°í™”\n",
        "plt.scatter(test_x[:,1], test_y, label=\"test data\")\n",
        "plt.plot(test_x[:,1], model.predict(test_x), 'r-', label=\"model\")\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f5dlfkkLQjXD"
      },
      "outputs": [],
      "source": [
        "# í‰ê°€\n",
        "def RMSE(pred, target):\n",
        "  error = pred - target\n",
        "  square = error * error\n",
        "  mean = np.mean(square)\n",
        "  root = np.sqrt(mean)\n",
        "  return root\n",
        "\n",
        "pred = model.predict(train_x)\n",
        "print(\"Train RMSE =\", RMSE(pred, train_y))\n",
        "\n",
        "pred = model.predict(test_x)\n",
        "print(\"Test RMSE =\", RMSE(pred, test_y))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omIluYozJrBD"
      },
      "source": [
        "## Linear Regressionì˜ Analytical Solution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x4Mnm49oL3EW"
      },
      "outputs": [],
      "source": [
        "# ë°ì´í„° ì¤€ë¹„\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import make_regression\n",
        "\n",
        "X, y = make_regression(n_samples=100, n_features=1,\n",
        "                       bias=100, noise=40, random_state=1)\n",
        "\n",
        "\n",
        "# ë°ì´í„° ì‹œê°í™”\n",
        "plt.scatter(X, y, label=\"data\")\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dM5xuBPtL3Ed"
      },
      "outputs": [],
      "source": [
        "# biasë¥¼ í•œë²ˆì— ê³„ì‚°í•˜ê¸° ìœ„í•´, 1ì„ Xì— ì¶”ê°€í•´ ì¤ë‹ˆë‹¤.\n",
        "new_X = np.insert(X, 0, 1, axis=1)\n",
        "\n",
        "# train, test ë‚˜ëˆ”\n",
        "train_x, test_x, train_y, test_y = train_test_split(new_X, y, test_size=0.3, shuffle=True, random_state=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IayUx_RkL3Ee"
      },
      "outputs": [],
      "source": [
        "# Normal Equation\n",
        "# Inverse: np.linalg.inv()\n",
        "# Mat. Multiplication: np.matmul()\n",
        "first = None\n",
        "second = None\n",
        "W = None\n",
        "\n",
        "pred_train = None # train setì— ëŒ€í•œ ì˜ˆì¸¡ ê°’\n",
        "pred_test = None # test setì— ëŒ€í•œ ì˜ˆì¸¡ ê°’"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ì •ë‹µì½”ë“œ: Normal Equation\n",
        "first = np.linalg.inv(np.matmul(train_x.T, train_x))\n",
        "second = np.matmul(train_x.T, train_y)\n",
        "W = np.matmul(first, second)\n",
        "\n",
        "pred_train = np.matmul(train_x, W)\n",
        "pred_test = np.matmul(test_x, W)"
      ],
      "metadata": {
        "id": "_cy4vQapThmj",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JJAsqG1yL3Ee"
      },
      "outputs": [],
      "source": [
        "# train dataì— ëŒ€í•œ í•™ìŠµ ëª¨ë¸ ì‹œê°í™”\n",
        "plt.scatter(train_x[:,1], train_y, label=\"train data\")\n",
        "plt.plot(train_x[:,1], pred_train, 'r-', label=\"model\")\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T3hrVCdbL3Ef"
      },
      "outputs": [],
      "source": [
        "# test dataì— ëŒ€í•œ í•™ìŠµ ëª¨ë¸ ì‹œê°í™”\n",
        "plt.scatter(test_x[:,1], test_y, label=\"test data\")\n",
        "plt.plot(test_x[:,1], pred_test, 'r',  label=\"model\")\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uOLEXknAL3Ef"
      },
      "outputs": [],
      "source": [
        "# í‰ê°€\n",
        "def RMSE(pred, target):\n",
        "  error = pred - target\n",
        "  square = error * error\n",
        "  mean = np.mean(square)\n",
        "  root = np.sqrt(mean)\n",
        "  return root\n",
        "\n",
        "print(\"Train RMSE =\", RMSE(pred_train, train_y))\n",
        "\n",
        "print(\"Test RMSE =\", RMSE(pred_test, test_y))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2b3rrYTkaTo2"
      },
      "source": [
        "## ë‹¹ë‡¨ë³‘ ë°ì´í„°ì—ì„œ, SKLearn, Numerical Solution, Analytical Solution ë¹„êµ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qNowAJb-uO30"
      },
      "outputs": [],
      "source": [
        "# ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "from sklearn.datasets import load_diabetes\n",
        "datasets = load_diabetes()\n",
        "\n",
        "# biasë¥¼ í•œë²ˆì— ê³„ì‚°í•˜ê¸° ìœ„í•´, 1ì„ Xì— ì¶”ê°€í•´ ì¤ë‹ˆë‹¤.\n",
        "new_X = np.insert(datasets.data, 0, 1, axis=1)\n",
        "\n",
        "# train, test ë‚˜ëˆ”\n",
        "train_x, test_x, train_y, test_y = train_test_split(new_X, datasets.target, test_size=0.3, shuffle=True, random_state=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nb0cYU3guO31"
      },
      "outputs": [],
      "source": [
        "# Scikit-Learn ìœ¼ë¡œ í•™ìŠµ\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "simple_linear = LinearRegression()\n",
        "simple_linear.fit(train_x, train_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "37CrFS9nu05e"
      },
      "outputs": [],
      "source": [
        "# í‰ê°€\n",
        "def RMSE(pred, target):\n",
        "  error = pred - target\n",
        "  square = error * error\n",
        "  mean = np.mean(square)\n",
        "  root = np.sqrt(mean)\n",
        "  return root\n",
        "\n",
        "pred = simple_linear.predict(train_x)\n",
        "print(\"Train RMSE =\", RMSE(pred, train_y))\n",
        "\n",
        "pred = simple_linear.predict(test_x)\n",
        "print(\"Test RMSE =\", RMSE(pred, test_y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_j8ZBD_Sxr4n"
      },
      "outputs": [],
      "source": [
        "# TODO: Numerical Solution ì½”ë“œ ì¶”ê°€í•˜ê¸°"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJcur2f1xopy"
      },
      "outputs": [],
      "source": [
        "# TODO: Analytical Solution ì½”ë“œ ì¶”ê°€í•˜ê¸°"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mUPo4utx6MM"
      },
      "source": [
        "## í–‰ë³µì§€ìˆ˜ ë°ì´í„°ì—ì„œ, SKLearn, Numerical Solution, Analytical Solution ë¹„êµ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fd7-rfh8yUOX"
      },
      "outputs": [],
      "source": [
        "import os                            # ë°ì´í„° íŒŒì¼ ê²½ë¡œ ì„¤ì •\n",
        "import csv                           # ë°ì´í„° íŒŒì¼ ë¡œë“œ\n",
        "\n",
        "def Load_Dataset(filename):\n",
        "    with open(filename, 'r') as f:\n",
        "        csv_reader = csv.reader(f)                  # íŒŒì¼ ë¡œë“œ\n",
        "        header = next(csv_reader)\n",
        "\n",
        "        x_data = []\n",
        "        y_data = []\n",
        "        for line in csv_reader:\n",
        "            features = line[6:]\n",
        "            x = [1.0] + [float(i) for i in features]\n",
        "            y = float(line[2])\n",
        "            x_data.append(x)\n",
        "            y_data.append(y)\n",
        "\n",
        "        x_array = np.array(x_data)\n",
        "        y_array = np.array(y_data)\n",
        "\n",
        "    return header, x_array, y_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j0noCMGByG9x"
      },
      "outputs": [],
      "source": [
        "# ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "_, train_x, train_y = Load_Dataset('/content/happiness_train.csv')\n",
        "_, test_x, test_y = Load_Dataset('/content/happiness_test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VYWHZ0ZuyG92"
      },
      "outputs": [],
      "source": [
        "# Scikit-Learn ìœ¼ë¡œ í•™ìŠµ\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "simple_linear = LinearRegression()\n",
        "simple_linear.fit(train_x, train_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HTX8AXGHyG93"
      },
      "outputs": [],
      "source": [
        "# í‰ê°€\n",
        "def RMSE(pred, target):\n",
        "  error = pred - target\n",
        "  square = error * error\n",
        "  mean = np.mean(square)\n",
        "  root = np.sqrt(mean)\n",
        "  return root\n",
        "\n",
        "pred = simple_linear.predict(train_x)\n",
        "print(\"Train RMSE =\", RMSE(pred, train_y))\n",
        "\n",
        "pred = simple_linear.predict(test_x)\n",
        "print(\"Test RMSE =\", RMSE(pred, test_y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YV89dFZb1GpO"
      },
      "outputs": [],
      "source": [
        "# TODO: Numerical Solution ì½”ë“œ ì¶”ê°€í•˜ê¸°"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P01_FrVb1GpI"
      },
      "outputs": [],
      "source": [
        "# TODO: Analytical Solution ì½”ë“œ ì¶”ê°€í•˜ê¸°"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBAB3GXmNKrv"
      },
      "source": [
        "# 2. Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLYtHfmPNKrw"
      },
      "source": [
        "## SKLearnì„ ì´ìš©í•œ Logistic Regression ì‚´í´ë³´ê¸°"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J7hOippjiSWu"
      },
      "outputs": [],
      "source": [
        "# ë°ì´í„° ì¤€ë¹„\n",
        "import os                            # ë°ì´í„° íŒŒì¼ ê²½ë¡œ ì„¤ì •\n",
        "import csv                           # ë°ì´í„° íŒŒì¼ ë¡œë“œ\n",
        "import numpy as np                   # numpy í–‰ë ¬ ì¡°ì‘\n",
        "import matplotlib.pyplot as plt      # ê·¸ë˜í”„ ê·¸ë¦¬ê¸°(ì„ íƒ ì‚¬í•­)\n",
        "\n",
        "def Load_Iris_Dataset(filename):\n",
        "    with open(filename, 'r') as f:\n",
        "        csv_reader = csv.reader(f)                  # íŒŒì¼ ë¡œë“œ\n",
        "        header = next(csv_reader)\n",
        "\n",
        "        x_data = []\n",
        "        y_data = []\n",
        "        for line in csv_reader:\n",
        "            features = line[1]\n",
        "            x = [1] + [float(features)]    # x_dataì— biasë¥¼ ìœ„í•œ 1ì¶”ê°€\n",
        "            y = float(line[0])\n",
        "\n",
        "            x_data.append(x)\n",
        "            y_data.append(y)\n",
        "\n",
        "        x_array = np.array(x_data)\n",
        "        y_array = np.array(y_data)\n",
        "\n",
        "    return header, x_array, y_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "URdRm_p4NKrw"
      },
      "outputs": [],
      "source": [
        "_, x_train, y_train = Load_Iris_Dataset('./Iris_Train.csv')\n",
        "_, x_test, y_test = Load_Iris_Dataset('./Iris_Test.csv')\n",
        "\n",
        "\n",
        "# train ë°ì´í„° ì‹œê°í™”\n",
        "is_virginica_x = x_train[y_train == 1]\n",
        "is_virginica_y = y_train[y_train == 1]\n",
        "\n",
        "not_virginica_x = x_train[y_train == 0]\n",
        "not_virginica_y = y_train[y_train == 0]\n",
        "\n",
        "plt.scatter(is_virginica_x[:, 1], is_virginica_y, color='b', label='Iris-Virginica')\n",
        "plt.scatter(not_virginica_x[:, 1], not_virginica_y, color='r', label='Not Iris-Virginica')\n",
        "\n",
        "plt.xlabel(\"Petal width\", fontsize=14)\n",
        "plt.ylabel(\"Class\", fontsize=14)\n",
        "plt.legend(loc=\"upper left\", fontsize=10)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LS0_GPqYNKrw"
      },
      "outputs": [],
      "source": [
        "# Scikit-Learn ìœ¼ë¡œ í•™ìŠµ\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lr = LogisticRegression()\n",
        "lr.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3DnYDQoINKrw"
      },
      "outputs": [],
      "source": [
        "# train dataì— ëŒ€í•œ í•™ìŠµ ëª¨ë¸ ì‹œê°í™”\n",
        "is_virginica_x = x_train[y_train == 1]\n",
        "is_virginica_y = y_train[y_train == 1]\n",
        "\n",
        "not_virginica_x = x_train[y_train == 0]\n",
        "not_virginica_y = y_train[y_train == 0]\n",
        "\n",
        "plot_feat = np.linspace(0, 3, 100).reshape(-1, 1)\n",
        "plot_x = np.insert(plot_feat, 0, 1, axis=1)\n",
        "plot_prob = lr.predict(plot_x)\n",
        "\n",
        "plt.scatter(is_virginica_x[:, 1], is_virginica_y, color='b', label='Iris-Virginica')\n",
        "plt.scatter(not_virginica_x[:, 1], not_virginica_y, color='r', label='Not Iris-Virginica')\n",
        "\n",
        "\n",
        "# ëª¨ë¸ì´ í•™ìŠµí•œ Probability\n",
        "plt.plot(plot_feat, plot_prob, 'g-', label='Hypothesis')\n",
        "\n",
        "plt.xlabel(\"Petal width\", fontsize=14)\n",
        "plt.ylabel(\"Probability\", fontsize=14)\n",
        "plt.legend(loc=\"upper left\", fontsize=10)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "blKGnzPDNKrw"
      },
      "outputs": [],
      "source": [
        "# í‰ê°€\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "y_pred = lr.predict(x_test)\n",
        "print('Test Accuracy: {:.2f}%'.format(accuracy_score(y_test, y_pred)*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tO9AAE58NKrx"
      },
      "source": [
        "## Numerical Solution êµ¬í˜„"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RC3zXuW1v-r8"
      },
      "outputs": [],
      "source": [
        "# ë°ì´í„° ì¤€ë¹„\n",
        "import os                            # ë°ì´í„° íŒŒì¼ ê²½ë¡œ ì„¤ì •\n",
        "import csv                           # ë°ì´í„° íŒŒì¼ ë¡œë“œ\n",
        "import numpy as np                   # numpy í–‰ë ¬ ì¡°ì‘\n",
        "import matplotlib.pyplot as plt      # ê·¸ë˜í”„ ê·¸ë¦¬ê¸°(ì„ íƒ ì‚¬í•­)\n",
        "\n",
        "def Load_Iris_Dataset(filename):\n",
        "    with open(filename, 'r') as f:\n",
        "        csv_reader = csv.reader(f)                  # íŒŒì¼ ë¡œë“œ\n",
        "        header = next(csv_reader)\n",
        "\n",
        "        x_data = []\n",
        "        y_data = []\n",
        "        for line in csv_reader:\n",
        "            features = line[1]\n",
        "            x = [1] + [float(features)]    # x_dataì— biasë¥¼ ìœ„í•œ 1ì¶”ê°€\n",
        "            y = float(line[0])\n",
        "\n",
        "            x_data.append(x)\n",
        "            y_data.append(y)\n",
        "\n",
        "        x_array = np.array(x_data)\n",
        "        y_array = np.array(y_data)\n",
        "\n",
        "    return header, x_array, y_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tLffsZtJv-r8"
      },
      "outputs": [],
      "source": [
        "_, x_train, y_train = Load_Iris_Dataset('./Iris_Train.csv')\n",
        "_, x_test, y_test = Load_Iris_Dataset('./Iris_Test.csv')\n",
        "\n",
        "\n",
        "# train ë°ì´í„° ì‹œê°í™”\n",
        "is_virginica_x = x_train[y_train == 1]\n",
        "is_virginica_y = y_train[y_train == 1]\n",
        "\n",
        "not_virginica_x = x_train[y_train == 0]\n",
        "not_virginica_y = y_train[y_train == 0]\n",
        "\n",
        "plt.scatter(is_virginica_x[:, 1], is_virginica_y, color='b', label='Iris-Virginica')\n",
        "plt.scatter(not_virginica_x[:, 1], not_virginica_y, color='r', label='Not Iris-Virginica')\n",
        "\n",
        "plt.xlabel(\"Petal width\", fontsize=14)\n",
        "plt.ylabel(\"Class\", fontsize=14)\n",
        "plt.legend(loc=\"upper left\", fontsize=10)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJ7KurljjWkq"
      },
      "source": [
        "### ëª¨ë¸ ì •ì˜\n",
        "1.   __\\_\\_init\\_\\___\n",
        "\n",
        "\n",
        "> *   ì¸ì: ëª¨ë¸ ì„¤ì •\n",
        "*   ì¶œë ¥: x\n",
        "*   ê¸°ëŠ¥: ëª¨ë¸ ì´ˆê¸°í™”\n",
        "\n",
        "> weight *W*ë¥¼ randomí•˜ê²Œ initialization\n",
        "\n",
        "2.   __train__\n",
        "\n",
        "\n",
        "> *   ì…ë ¥: í•™ìŠµë°ì´í„°, í•™ìŠµ ì„¤ì •\n",
        "*   ì¶œë ¥: Loss\n",
        "*   ê¸°ëŠ¥: ë°ì´í„°ë¡œ ëª¨ë¸ í•™ìŠµ\n",
        "\n",
        "> ë§¤ epochë§ˆë‹¤ ì „ì²´ ë°ì´í„°ì— ëŒ€í•´ loss, grad ê³„ì‚°í•˜ì—¬ í•™ìŠµ\n",
        "\n",
        "\n",
        "3. __predict__\n",
        "\n",
        "> *   ì…ë ¥: ê²€ì¦ ë°ì´í„°\n",
        "*   ì¶œë ¥: ëª¨ë¸ì˜ ì˜ˆì¸¡ê°’\n",
        "*   ê¸°ëŠ¥: trainë¡œ í•™ìŠµëœ ëª¨ë¸ë¡œ ê²€ì¦, ì˜ˆì¸¡ê°’ ìƒì„±\n",
        "\n",
        "> ê²€ì¦ ë°ì´í„°ì— ëŒ€í•´ ë¶„ë¥˜ ì˜ˆì¸¡ ê²°ê³¼ ì‚°ì¶œ\n",
        "\n",
        "4. ___sigmoid__\n",
        "\n",
        "> *   ì…ë ¥: ì‹¤ìˆ˜í˜• numpy array\n",
        "*   ì¶œë ¥: sigmoidë¥¼ ì·¨í•œ array\n",
        "*   ê¸°ëŠ¥: ì£¼ì–´ì§„ arrayì— ëŒ€í•œ ëª¨ë“  sigmoid ê°’ ê³„ì‚°\n",
        "\n",
        "> $sigmoid(x) =\\frac{1}{ 1+e^{-(x)}}$\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "both",
        "id": "mTCU7B8tkx2S"
      },
      "outputs": [],
      "source": [
        "class LogisticRegression:\n",
        "    def __init__(self, num_features, seed):\n",
        "        np.random.seed(seed)\n",
        "        self.W = np.random.rand(num_features, 1)\n",
        "\n",
        "    def train(self, train_x, train_y, num_epochs, learning_rate):\n",
        "        loss_memory = []\n",
        "        train_y = np.expand_dims(train_y, 1)\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "          # prediction ê³„ì‚° ğ‘¿^ğ‘» ğ‘¾\n",
        "          prediction = np.matmul(train_x, self.W)\n",
        "\n",
        "          # sigmoid ì ìš©\n",
        "          prob = self._sigmoid(prediction)\n",
        "\n",
        "          # Loss ê³„ì‚°\n",
        "          error = prob - train_y\n",
        "          loss = - np.mean(train_y * np.log(prob) + (1 - train_y) * np.log(1 - prob))\n",
        "\n",
        "          # Gradient ê³„ì‚°\n",
        "          grad = np.mean(train_x * error, axis=0, keepdims=True).T\n",
        "\n",
        "          # Weight Update\n",
        "          self.W -= grad * learning_rate\n",
        "\n",
        "          loss_memory.append(loss)\n",
        "        return loss_memory\n",
        "\n",
        "    def predict_prob(self, test_x):\n",
        "        prob = self._sigmoid(np.matmul(test_x, self.W))\n",
        "        return prob.flatten()\n",
        "\n",
        "    def predict(self, test_x):\n",
        "        prob = self._sigmoid(np.matmul(test_x, self.W))\n",
        "        prob = prob.flatten()\n",
        "        y_pred_one_or_zero = []\n",
        "        for y in prob:\n",
        "            if y > 0.5:\n",
        "                y_pred_one_or_zero.append(1)\n",
        "            else:\n",
        "                y_pred_one_or_zero.append(0)\n",
        "        return y_pred_one_or_zero\n",
        "\n",
        "    def _sigmoid(self, x):\n",
        "        return 1 / (1 + np.exp(-x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IBt5hJWkzK8g"
      },
      "outputs": [],
      "source": [
        "# Hyper-parameter ì„¤ì • ë° í•™ìŠµ\n",
        "num_epochs = 1000\n",
        "learning_rate = 1e-1\n",
        "seed = 2\n",
        "\n",
        "# Training\n",
        "num_data, num_features = x_train.shape\n",
        "\n",
        "model = LogisticRegression(num_features, seed)\n",
        "loss_memory = model.train(x_train, y_train, num_epochs, learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eB_0wtckza9D"
      },
      "outputs": [],
      "source": [
        "# Plot Loss\n",
        "x_axis = list(range(num_epochs))\n",
        "\n",
        "plt.plot(x_axis, loss_memory)\n",
        "plt.title('Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('MSE Loss')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tBqV4GWc1CzM"
      },
      "outputs": [],
      "source": [
        "# train dataì— ëŒ€í•œ í•™ìŠµ ëª¨ë¸ ì‹œê°í™”\n",
        "is_virginica_x = x_train[y_train == 1]\n",
        "is_virginica_y = y_train[y_train == 1]\n",
        "\n",
        "not_virginica_x = x_train[y_train == 0]\n",
        "not_virginica_y = y_train[y_train == 0]\n",
        "\n",
        "plot_feat = np.linspace(0, 3, 100).reshape(-1, 1)\n",
        "plot_x = np.insert(plot_feat, 0, 1, axis=1)\n",
        "plot_prob = model.predict_prob(plot_x)\n",
        "\n",
        "plt.scatter(is_virginica_x[:, 1], is_virginica_y, color='b', label='Iris-Virginica')\n",
        "plt.scatter(not_virginica_x[:, 1], not_virginica_y, color='r', label='Not Iris-Virginica')\n",
        "\n",
        "# ëª¨ë¸ì´ í•™ìŠµí•œ Probability\n",
        "plt.plot(plot_feat, plot_prob, 'g-', label='Hypothesis')\n",
        "\n",
        "plt.xlabel(\"Petal width\", fontsize=14)\n",
        "plt.ylabel(\"Probability\", fontsize=14)\n",
        "plt.legend(loc=\"upper left\", fontsize=10)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kOjimBnwAYOM"
      },
      "outputs": [],
      "source": [
        "# train dataì— ëŒ€í•œ í•™ìŠµ ëª¨ë¸ ì‹œê°í™”\n",
        "is_virginica_x = x_train[y_train == 1]\n",
        "is_virginica_y = y_train[y_train == 1]\n",
        "\n",
        "not_virginica_x = x_train[y_train == 0]\n",
        "not_virginica_y = y_train[y_train == 0]\n",
        "\n",
        "plot_feat = np.linspace(0, 3, 100).reshape(-1, 1)\n",
        "plot_x = np.insert(plot_feat, 0, 1, axis=1)\n",
        "plot_prob = model.predict(plot_x)\n",
        "\n",
        "plt.scatter(is_virginica_x[:, 1], is_virginica_y, color='b', label='Iris-Virginica')\n",
        "plt.scatter(not_virginica_x[:, 1], not_virginica_y, color='r', label='Not Iris-Virginica')\n",
        "\n",
        "# ëª¨ë¸ì´ í•™ìŠµí•œ Probability\n",
        "plt.plot(plot_feat, plot_prob, 'g-', label='Hypothesis')\n",
        "\n",
        "plt.xlabel(\"Petal width\", fontsize=14)\n",
        "plt.ylabel(\"Probability\", fontsize=14)\n",
        "plt.legend(loc=\"upper left\", fontsize=10)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-1iNKRE1Ous"
      },
      "outputs": [],
      "source": [
        "# í‰ê°€\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "y_pred = model.predict(x_test)\n",
        "print('Test Accuracy: {:.2f}%'.format(accuracy_score(y_test, y_pred)*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgEnvzmMNKry"
      },
      "source": [
        "## ìŠ¤íŒ¸ë©”ì¼ ë°ì´í„°ì—ì„œ SKLearnê³¼ Numerical solution ë¹„êµ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QCGKydaicskb"
      },
      "outputs": [],
      "source": [
        "# ë°ì´í„° ì¤€ë¹„\n",
        "import os                            # ë°ì´í„° íŒŒì¼ ê²½ë¡œ ì„¤ì •\n",
        "import csv                           # ë°ì´í„° íŒŒì¼ ë¡œë“œ\n",
        "import numpy as np                   # numpy í–‰ë ¬ ì¡°ì‘\n",
        "\n",
        "def Load_Spam_Dataset(filename):\n",
        "    with open(filename, 'r') as f:\n",
        "        csv_reader = csv.reader(f)                  # íŒŒì¼ ë¡œë“œ\n",
        "        header = next(csv_reader)\n",
        "\n",
        "        x_data = []\n",
        "        y_data = []\n",
        "        for line in csv_reader:\n",
        "            features = line[:-1]\n",
        "            x = [1] + list(map(float, features))   # x_dataì— biasë¥¼ ìœ„í•œ 1ì¶”ê°€\n",
        "            y = float(line[-1])\n",
        "\n",
        "            x_data.append(x)\n",
        "            y_data.append(y)\n",
        "\n",
        "        x_array = np.array(x_data)\n",
        "        y_array = np.array(y_data)\n",
        "\n",
        "    return header, x_array, y_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j8LMdIMVGm6R"
      },
      "outputs": [],
      "source": [
        "_, x_train, y_train = Load_Spam_Dataset('./Spam_train.csv')\n",
        "_, x_test, y_test = Load_Spam_Dataset('./Spam_test.csv')\n",
        "\n",
        "print(x_train.shape) # ë°ì´í„° ìˆ˜, feature ìˆ˜\n",
        "print(y_train.shape) # ë°ì´í„° ìˆ˜"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M8g0mAwfGm6T"
      },
      "outputs": [],
      "source": [
        "# Logistic regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lr = LogisticRegression(max_iter=10000)\n",
        "lr.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ZK3WQ6xHRAR"
      },
      "outputs": [],
      "source": [
        "# í‰ê°€\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "y_pred = lr.predict(x_test)\n",
        "print('Test Accuracy: {:.2f}%'.format(accuracy_score(y_test, y_pred)*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kh3xZtanICFT"
      },
      "outputs": [],
      "source": [
        "# TODO: Numerical solution êµ¬í˜„ ë° í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFTkOf31KUDv"
      },
      "source": [
        "## ìœ ë°©ì•” ë°ì´í„°ì—ì„œ SKLearnê³¼ Numerical solution ë¹„êµ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pACyXa90KUDx"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "cancer = load_breast_cancer()\n",
        "print(cancer.feature_names) # feature ì´ë¦„ ì¶œë ¥\n",
        "\n",
        "# biasë¥¼ í•œë²ˆì— ê³„ì‚°í•˜ê¸° ìœ„í•´, 1ì„ Xì— ì¶”ê°€í•´ ì¤ë‹ˆë‹¤.\n",
        "import numpy as np\n",
        "new_X = np.insert(cancer.data, 0, 1, axis=1)\n",
        "\n",
        "# train, test ë‚˜ëˆ”\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(new_X, cancer.target, test_size=0.3, shuffle=True, random_state=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y1Be9Ru0LE58"
      },
      "outputs": [],
      "source": [
        "# Logistic regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lr = LogisticRegression(max_iter=10000)\n",
        "lr.fit(x_train, y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MNk6ta3rKUDy"
      },
      "outputs": [],
      "source": [
        "# í‰ê°€\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "y_pred = lr.predict(x_test)\n",
        "print('Test Accuracy: {:.2f}%'.format(accuracy_score(y_test, y_pred)*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gnYw8rUBLwg0"
      },
      "outputs": [],
      "source": [
        "# TODO: Numerical solution êµ¬í˜„ ë° í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2y5av-MJdZQ"
      },
      "source": [
        "# 3. Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_OubnXR2JgKp"
      },
      "outputs": [],
      "source": [
        "# ë°ì´í„° ì¤€ë¹„\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# ìœ ë°©ì•”(Breast Cancer) í™˜ì ë°ì´í„°, 569ê°œ ë°ì´í„°, 30ê°œì˜ feature, í™˜ì class 2 (ìŒì„±, ì–‘ì„±)\n",
        "cancer = load_breast_cancer()\n",
        "\n",
        "x = cancer.data\n",
        "y = cancer.target\n",
        "print(cancer.feature_names)\n",
        "\n",
        "# train, test ë‚˜ëˆ”\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, shuffle=True, random_state=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BFNFcyJfKvih"
      },
      "outputs": [],
      "source": [
        "# ëª¨ë¸ í•™ìŠµ\n",
        "depth=3\n",
        "max_leaf_nodes=10\n",
        "model = DecisionTreeClassifier(criterion='entropy', max_depth=depth, max_leaf_nodes=max_leaf_nodes, random_state=2021) # decision tree\n",
        "# model = RandomForestClassifier(criterion='entropy', max_depth=depth, max_leaf_nodes=max_leaf_nodes, random_state=2021) # random forest\n",
        "\n",
        "model.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ndme3mxK4Q3"
      },
      "outputs": [],
      "source": [
        "# ëª¨ë¸ í‰ê°€\n",
        "pred = model.predict(x_test)\n",
        "print(\"Accuracy: %.6f\" % accuracy_score(y_true=y_test, y_pred=pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kY8sYYnbK-SS"
      },
      "outputs": [],
      "source": [
        "# ëª¨ë¸ ë¶„ì„\n",
        "\n",
        "from sklearn.tree import plot_tree, export_text\n",
        "from IPython import display\n",
        "\n",
        "feature_names = cancer.feature_names\n",
        "target_names = cancer.target_names\n",
        "\n",
        "# ì‹œê°í™”(í…ìŠ¤íŠ¸)\n",
        "text_representation = export_text(model)\n",
        "print(text_representation)\n",
        "\n",
        "\n",
        "# ì‹œê°í™”(ê·¸ë¦¼)\n",
        "plt.figure(figsize=(20,20))\n",
        "tree_plot = plot_tree(model,\n",
        "                      feature_names=feature_names,\n",
        "                      class_names = target_names,\n",
        "                      label = 'all',\n",
        "                      rounded=True,\n",
        "                      proportion = True,\n",
        "                      filled=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "heJEfFoXLitp"
      },
      "outputs": [],
      "source": [
        "#  Depthì— ë”°ë¥¸ ì •í™•ë„ ë³€í™”\n",
        "accuracy = []\n",
        "max_depth=10\n",
        "max_leaf_nodes=10\n",
        "\n",
        "# depth 1ë¶€í„° 10ê¹Œì§€\n",
        "for depth in range(1, max_depth + 1):\n",
        "    model = DecisionTreeClassifier(criterion='entropy', max_depth=depth, max_leaf_nodes=max_leaf_nodes, random_state=2021)\n",
        "    # model = RandomForestClassifier(criterion='entropy', max_depth=depth, max_leaf_nodes=max_leaf_nodes, random_state=2021)\n",
        "    model.fit(x_train, y_train)\n",
        "\n",
        "    pred = model.predict(x_test)\n",
        "\n",
        "    acc = accuracy_score(y_true=y_test, y_pred=pred)\n",
        "    accuracy.append(acc)\n",
        "\n",
        "# ì‹œê°í™”\n",
        "plt.plot(list(range(1, max_depth + 1)), accuracy)\n",
        "plt.xlabel('Depth')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z6wY7CzI1uaw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCMc_jRmch31"
      },
      "source": [
        "## ì™€ì¸ ë°ì´í„°ì—ì„œì˜ Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8STF9_W2coHm"
      },
      "outputs": [],
      "source": [
        "# ì™€ì¸ ë°ì´í„°, 178ê°œ ë°ì´í„°, 13ê°œì˜ feature, ì™€ì¸ ì¢…ë¥˜ 3ê°€ì§€\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "wine = load_wine()\n",
        "\n",
        "x = wine.data\n",
        "y = wine.target\n",
        "\n",
        "# train, test ë‚˜ëˆ”\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, shuffle=True, random_state=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RPQtbUFQZluK"
      },
      "outputs": [],
      "source": [
        "# Tree ê¸°ë°˜ ëª¨ë¸\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# ëª¨ë¸ íŠœë‹\n",
        "depth=3\n",
        "max_leaf_nodes=10\n",
        "model = DecisionTreeClassifier(criterion='entropy', max_depth=depth, max_leaf_nodes=max_leaf_nodes, random_state=2021) # decision tree\n",
        "# model = RandomForestClassifier(criterion='entropy', max_depth=depth, max_leaf_nodes=max_leaf_nodes, random_state=2021) # random forest\n",
        "\n",
        "# ëª¨ë¸ í•™ìŠµ\n",
        "model.fit(x_train, y_train)\n",
        "\n",
        "# ëª¨ë¸ í‰ê°€\n",
        "pred = model.predict(x_test)\n",
        "print(\"Accuracy: %.6f\" % accuracy_score(y_true=y_test, y_pred=pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uC00WgtOcrW9"
      },
      "source": [
        "## ìŠ¤íŒ¸ ë°ì´í„°ì—ì„œì˜ Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CtI699W9crXC"
      },
      "outputs": [],
      "source": [
        "# ë°ì´í„° ì¤€ë¹„\n",
        "import os                            # ë°ì´í„° íŒŒì¼ ê²½ë¡œ ì„¤ì •\n",
        "import csv                           # ë°ì´í„° íŒŒì¼ ë¡œë“œ\n",
        "import numpy as np                   # numpy í–‰ë ¬ ì¡°ì‘\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def Load_Spam_Dataset(filename):\n",
        "    with open(filename, 'r') as f:\n",
        "        csv_reader = csv.reader(f)                  # íŒŒì¼ ë¡œë“œ\n",
        "        header = next(csv_reader)\n",
        "\n",
        "        x_data = []\n",
        "        y_data = []\n",
        "        for line in csv_reader:\n",
        "            features = line[:-1]\n",
        "            x = [1] + list(map(float, features))   # x_dataì— biasë¥¼ ìœ„í•œ 1ì¶”ê°€\n",
        "            y = float(line[-1])\n",
        "\n",
        "            x_data.append(x)\n",
        "            y_data.append(y)\n",
        "\n",
        "        x_array = np.array(x_data)\n",
        "        y_array = np.array(y_data)\n",
        "\n",
        "    return header, x_array, y_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0iqcT1pLYPSL"
      },
      "outputs": [],
      "source": [
        "_, x_train, y_train = Load_Spam_Dataset('./Spam_train.csv')\n",
        "_, x_test, y_test = Load_Spam_Dataset('./Spam_test.csv')\n",
        "\n",
        "print(x_train.shape) # ë°ì´í„° ìˆ˜, feature ìˆ˜\n",
        "print(y_train.shape) # ë°ì´í„° ìˆ˜"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "weafF319YWhw"
      },
      "outputs": [],
      "source": [
        "# Tree ê¸°ë°˜ ëª¨ë¸\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "depth=3\n",
        "max_leaf_nodes=10\n",
        "model = DecisionTreeClassifier(criterion='entropy', max_depth=depth, max_leaf_nodes=max_leaf_nodes, random_state=2021) # decision tree\n",
        "# model = RandomForestClassifier(criterion='entropy', max_depth=depth, max_leaf_nodes=max_leaf_nodes, random_state=2021) # random forest\n",
        "\n",
        "# ëª¨ë¸ í•™ìŠµ\n",
        "model.fit(x_train, y_train)\n",
        "\n",
        "# ëª¨ë¸ í‰ê°€\n",
        "pred = model.predict(x_test)\n",
        "print(\"Accuracy: %.6f\" % accuracy_score(y_true=y_test, y_pred=pred))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}