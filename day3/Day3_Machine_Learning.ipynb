{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Lab 3. Machine Learning - Linear and Logistic Regression, and Decision Tree\n",
        "\n",
        "## Table of Contents\n",
        "- Linear regression\n",
        "- Logistic regression\n",
        "- Decision Tree"
      ],
      "metadata": {
        "id": "9pEOVQePMPkj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download dataset"
      ],
      "metadata": {
        "id": "k8VXRdiGM-KO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "# happiness\n",
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1g-kEqWUe7zYGrxQ2tGTcuT5MN4XDCXFX' -O happiness_train.csv\n",
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1bFKKosFdHXGvU5lPIyjjnhv-aS5aPLj1' -O happiness_test.csv\n",
        "# iris\n",
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1vThUwXXgL_PtMpYq5PfVlygtLD46I6kA' -O Iris_Train.csv\n",
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1wdwS1iksXAkHlVa3aZwzpkYapATb5nZr' -O Iris_Test.csv\n",
        "# spam\n",
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=19KW6xooGxbUOq-f6C-5U3_0qhfmcY7zp' -O Spam_train.csv\n",
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1VyD2cL8GSyr8tkpWk8XsgbhpR-W10rpp' -O Spam_test.csv\n",
        "# titanic\n",
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1Afn3qiznaOEX437j5lEIV8SVmCwqy1Rl' -O Titanic_train.csv\n",
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1CgDkX3xT53xwxTeUOI6MT0YqO2L9mfV4' -O Titanic_test.csv"
      ],
      "metadata": {
        "id": "mnYfKNcPQNeo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import packages"
      ],
      "metadata": {
        "id": "Ea0Y6JuFNErD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import copy\n",
        "from os.path import join\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "np.random.seed(0)"
      ],
      "metadata": {
        "id": "FtQz1GYPMyWn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0p7ZixCu93-Z"
      },
      "source": [
        "# 1. Linear Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ubdhvk9U97af"
      },
      "source": [
        "## SKLearn을 이용한 Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VcoE64FB-pzS"
      },
      "outputs": [],
      "source": [
        "# 데이터 준비\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import make_regression\n",
        "\n",
        "X, y = make_regression(n_samples=100, n_features=1,\n",
        "                       bias=100, noise=40, random_state=1)\n",
        "\n",
        "\n",
        "# 데이터 시각화\n",
        "plt.scatter(X, y, label=\"data\")\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5JrDghIv_xTI"
      },
      "outputs": [],
      "source": [
        "# bias를 한번에 계산하기 위해, 1을 X에 추가해 줍니다.\n",
        "new_X = np.insert(X, 0, 1, axis=1)\n",
        "\n",
        "# train, test 나눔\n",
        "train_x, test_x, train_y, test_y = train_test_split(new_X, y, test_size=0.3, shuffle=True, random_state=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x7mBSxLf_agG"
      },
      "outputs": [],
      "source": [
        "# Scikit-Learn 으로 학습\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "simple_linear = LinearRegression()\n",
        "simple_linear.fit(train_x, train_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "97R1qGz0Acph"
      },
      "outputs": [],
      "source": [
        "# train data에 대한 학습 모델 시각화\n",
        "plt.scatter(train_x[:,1], train_y, label=\"train data\")\n",
        "plt.plot(train_x[:,1], simple_linear.predict(train_x), 'r-', label=\"model\")\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5SmveKY8BnpE"
      },
      "outputs": [],
      "source": [
        "# test data에 대한 학습 모델 시각화\n",
        "plt.scatter(test_x[:,1], test_y, label=\"test data\")\n",
        "plt.plot(test_x[:,1], simple_linear.predict(test_x), 'r',  label=\"model\")\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o33OKDIX_kjH"
      },
      "outputs": [],
      "source": [
        "# 평가\n",
        "def RMSE(pred, target):\n",
        "  error = pred - target\n",
        "  square = error * error\n",
        "  mean = np.mean(square)\n",
        "  root = np.sqrt(mean)\n",
        "  return root\n",
        "\n",
        "pred = simple_linear.predict(train_x)\n",
        "print(\"Train RMSE =\", RMSE(pred, train_y))\n",
        "\n",
        "pred = simple_linear.predict(test_x)\n",
        "print(\"Test RMSE =\", RMSE(pred, test_y))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOXmn9BuQjXC"
      },
      "source": [
        "## Linear Regression의 Numerical Solution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z21Sbgy2QjXC"
      },
      "outputs": [],
      "source": [
        "# 데이터 준비\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import make_regression\n",
        "\n",
        "X, y = make_regression(n_samples=100, n_features=1,\n",
        "                       bias=100, noise=40, random_state=1)\n",
        "\n",
        "\n",
        "# 데이터 시각화\n",
        "plt.scatter(X, y, label=\"data\")\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tDW_fJnfQjXD"
      },
      "outputs": [],
      "source": [
        "# bias를 한번에 계산하기 위해, 1을 X에 추가해 줍니다.\n",
        "new_X = np.insert(X, 0, 1, axis=1)\n",
        "\n",
        "# train, test 나눔\n",
        "train_x, test_x, train_y, test_y = train_test_split(new_X, y, test_size=0.3, shuffle=True, random_state=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CfuvYeagQ7Hd"
      },
      "outputs": [],
      "source": [
        "class LinearRegression_gd:\n",
        "    def __init__(self, num_features, seed):\n",
        "        np.random.seed(seed)\n",
        "        self.W = np.random.rand(num_features, 1)\n",
        "\n",
        "    def train(self, train_x, train_y, num_epochs, learning_rate):\n",
        "        num_data, num_features = train_x.shape\n",
        "\n",
        "        loss_memory = []\n",
        "        train_y = np.expand_dims(train_y, 1)\n",
        "\n",
        "        for i in range(num_epochs):\n",
        "\n",
        "            # prediction 계산\n",
        "            prediction = np.matmul(train_x, self.W)\n",
        "\n",
        "            # Error 및 Loss 계산\n",
        "            error = prediction - train_y\n",
        "            loss = np.mean(error * error) / 2\n",
        "\n",
        "            # Gradient 계산\n",
        "            gradient= np.mean(train_x * error, axis=0, keepdims=True).T # 𝝏𝑳(𝒙, 𝑾)/𝝏𝑾\n",
        "\n",
        "            # Weight Update\n",
        "            # gradient, learning_rate 활용하여 self.W 업데이트\n",
        "            self.W -= learning_rate * gradient\n",
        "\n",
        "            # Loss ‘loss_memory’에 추가\n",
        "            loss_memory.append(loss)\n",
        "\n",
        "        # ‘loss_memory’ 반환\n",
        "        return loss_memory\n",
        "\n",
        "    def predict(self, test_x):\n",
        "        pred = np.matmul(test_x, self.W).squeeze()\n",
        "        return pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "htEMq4AaQjXD"
      },
      "outputs": [],
      "source": [
        "# Hyper-parameter\n",
        "num_epochs = 1500\n",
        "learning_rate = 0.01\n",
        "seed = 15\n",
        "\n",
        "num_data, num_features = train_x.shape\n",
        "model = LinearRegression_gd(num_features, seed)\n",
        "loss_memory = model.train(train_x, train_y, num_epochs, learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oXxV3FF4UfJ-"
      },
      "outputs": [],
      "source": [
        "# Plot Loss\n",
        "x_axis = list(range(num_epochs))\n",
        "\n",
        "plt.plot(x_axis, loss_memory)\n",
        "plt.title('Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('MSE Loss')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SZmAouvrQjXD"
      },
      "outputs": [],
      "source": [
        "# train data에 대한 학습 모델 시각화\n",
        "plt.scatter(train_x[:,1], train_y, label=\"train data\")\n",
        "plt.plot(train_x[:,1], model.predict(train_x), 'r-', label=\"model\")\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PYFICMDzQjXD"
      },
      "outputs": [],
      "source": [
        "# test data에 대한 학습 모델 시각화\n",
        "plt.scatter(test_x[:,1], test_y, label=\"test data\")\n",
        "plt.plot(test_x[:,1], model.predict(test_x), 'r-', label=\"model\")\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f5dlfkkLQjXD"
      },
      "outputs": [],
      "source": [
        "# 평가\n",
        "def RMSE(pred, target):\n",
        "  error = pred - target\n",
        "  square = error * error\n",
        "  mean = np.mean(square)\n",
        "  root = np.sqrt(mean)\n",
        "  return root\n",
        "\n",
        "pred = model.predict(train_x)\n",
        "print(\"Train RMSE =\", RMSE(pred, train_y))\n",
        "\n",
        "pred = model.predict(test_x)\n",
        "print(\"Test RMSE =\", RMSE(pred, test_y))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omIluYozJrBD"
      },
      "source": [
        "## Linear Regression의 Analytical Solution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x4Mnm49oL3EW"
      },
      "outputs": [],
      "source": [
        "# 데이터 준비\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import make_regression\n",
        "\n",
        "X, y = make_regression(n_samples=100, n_features=1,\n",
        "                       bias=100, noise=40, random_state=1)\n",
        "\n",
        "\n",
        "# 데이터 시각화\n",
        "plt.scatter(X, y, label=\"data\")\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dM5xuBPtL3Ed"
      },
      "outputs": [],
      "source": [
        "# bias를 한번에 계산하기 위해, 1을 X에 추가해 줍니다.\n",
        "new_X = np.insert(X, 0, 1, axis=1)\n",
        "\n",
        "# train, test 나눔\n",
        "train_x, test_x, train_y, test_y = train_test_split(new_X, y, test_size=0.3, shuffle=True, random_state=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IayUx_RkL3Ee"
      },
      "outputs": [],
      "source": [
        "# Normal Equation\n",
        "# Inverse: np.linalg.inv()\n",
        "# Mat. Multiplication: np.matmul()\n",
        "first = None\n",
        "second = None\n",
        "W = None\n",
        "\n",
        "pred_train = None # train set에 대한 예측 값\n",
        "pred_test = None # test set에 대한 예측 값"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 정답코드: Normal Equation\n",
        "first = np.linalg.inv(np.matmul(train_x.T, train_x))\n",
        "second = np.matmul(train_x.T, train_y)\n",
        "W = np.matmul(first, second)\n",
        "\n",
        "pred_train = np.matmul(train_x, W)\n",
        "pred_test = np.matmul(test_x, W)"
      ],
      "metadata": {
        "id": "_cy4vQapThmj",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JJAsqG1yL3Ee"
      },
      "outputs": [],
      "source": [
        "# train data에 대한 학습 모델 시각화\n",
        "plt.scatter(train_x[:,1], train_y, label=\"train data\")\n",
        "plt.plot(train_x[:,1], pred_train, 'r-', label=\"model\")\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T3hrVCdbL3Ef"
      },
      "outputs": [],
      "source": [
        "# test data에 대한 학습 모델 시각화\n",
        "plt.scatter(test_x[:,1], test_y, label=\"test data\")\n",
        "plt.plot(test_x[:,1], pred_test, 'r',  label=\"model\")\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uOLEXknAL3Ef"
      },
      "outputs": [],
      "source": [
        "# 평가\n",
        "def RMSE(pred, target):\n",
        "  error = pred - target\n",
        "  square = error * error\n",
        "  mean = np.mean(square)\n",
        "  root = np.sqrt(mean)\n",
        "  return root\n",
        "\n",
        "print(\"Train RMSE =\", RMSE(pred_train, train_y))\n",
        "\n",
        "print(\"Test RMSE =\", RMSE(pred_test, test_y))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2b3rrYTkaTo2"
      },
      "source": [
        "## 당뇨병 데이터에서, SKLearn, Numerical Solution, Analytical Solution 비교\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qNowAJb-uO30"
      },
      "outputs": [],
      "source": [
        "# 데이터 불러오기\n",
        "from sklearn.datasets import load_diabetes\n",
        "datasets = load_diabetes()\n",
        "\n",
        "# bias를 한번에 계산하기 위해, 1을 X에 추가해 줍니다.\n",
        "new_X = np.insert(datasets.data, 0, 1, axis=1)\n",
        "\n",
        "# train, test 나눔\n",
        "train_x, test_x, train_y, test_y = train_test_split(new_X, datasets.target, test_size=0.3, shuffle=True, random_state=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nb0cYU3guO31"
      },
      "outputs": [],
      "source": [
        "# Scikit-Learn 으로 학습\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "simple_linear = LinearRegression()\n",
        "simple_linear.fit(train_x, train_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "37CrFS9nu05e"
      },
      "outputs": [],
      "source": [
        "# 평가\n",
        "def RMSE(pred, target):\n",
        "  error = pred - target\n",
        "  square = error * error\n",
        "  mean = np.mean(square)\n",
        "  root = np.sqrt(mean)\n",
        "  return root\n",
        "\n",
        "pred = simple_linear.predict(train_x)\n",
        "print(\"Train RMSE =\", RMSE(pred, train_y))\n",
        "\n",
        "pred = simple_linear.predict(test_x)\n",
        "print(\"Test RMSE =\", RMSE(pred, test_y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_j8ZBD_Sxr4n"
      },
      "outputs": [],
      "source": [
        "# TODO: Numerical Solution 코드 추가하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJcur2f1xopy"
      },
      "outputs": [],
      "source": [
        "# TODO: Analytical Solution 코드 추가하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mUPo4utx6MM"
      },
      "source": [
        "## 행복지수 데이터에서, SKLearn, Numerical Solution, Analytical Solution 비교\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fd7-rfh8yUOX"
      },
      "outputs": [],
      "source": [
        "import os                            # 데이터 파일 경로 설정\n",
        "import csv                           # 데이터 파일 로드\n",
        "\n",
        "def Load_Dataset(filename):\n",
        "    with open(filename, 'r') as f:\n",
        "        csv_reader = csv.reader(f)                  # 파일 로드\n",
        "        header = next(csv_reader)\n",
        "\n",
        "        x_data = []\n",
        "        y_data = []\n",
        "        for line in csv_reader:\n",
        "            features = line[6:]\n",
        "            x = [1.0] + [float(i) for i in features]\n",
        "            y = float(line[2])\n",
        "            x_data.append(x)\n",
        "            y_data.append(y)\n",
        "\n",
        "        x_array = np.array(x_data)\n",
        "        y_array = np.array(y_data)\n",
        "\n",
        "    return header, x_array, y_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j0noCMGByG9x"
      },
      "outputs": [],
      "source": [
        "# 데이터 불러오기\n",
        "_, train_x, train_y = Load_Dataset('/content/happiness_train.csv')\n",
        "_, test_x, test_y = Load_Dataset('/content/happiness_test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VYWHZ0ZuyG92"
      },
      "outputs": [],
      "source": [
        "# Scikit-Learn 으로 학습\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "simple_linear = LinearRegression()\n",
        "simple_linear.fit(train_x, train_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HTX8AXGHyG93"
      },
      "outputs": [],
      "source": [
        "# 평가\n",
        "def RMSE(pred, target):\n",
        "  error = pred - target\n",
        "  square = error * error\n",
        "  mean = np.mean(square)\n",
        "  root = np.sqrt(mean)\n",
        "  return root\n",
        "\n",
        "pred = simple_linear.predict(train_x)\n",
        "print(\"Train RMSE =\", RMSE(pred, train_y))\n",
        "\n",
        "pred = simple_linear.predict(test_x)\n",
        "print(\"Test RMSE =\", RMSE(pred, test_y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YV89dFZb1GpO"
      },
      "outputs": [],
      "source": [
        "# TODO: Numerical Solution 코드 추가하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P01_FrVb1GpI"
      },
      "outputs": [],
      "source": [
        "# TODO: Analytical Solution 코드 추가하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBAB3GXmNKrv"
      },
      "source": [
        "# 2. Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLYtHfmPNKrw"
      },
      "source": [
        "## SKLearn을 이용한 Logistic Regression 살펴보기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J7hOippjiSWu"
      },
      "outputs": [],
      "source": [
        "# 데이터 준비\n",
        "import os                            # 데이터 파일 경로 설정\n",
        "import csv                           # 데이터 파일 로드\n",
        "import numpy as np                   # numpy 행렬 조작\n",
        "import matplotlib.pyplot as plt      # 그래프 그리기(선택 사항)\n",
        "\n",
        "def Load_Iris_Dataset(filename):\n",
        "    with open(filename, 'r') as f:\n",
        "        csv_reader = csv.reader(f)                  # 파일 로드\n",
        "        header = next(csv_reader)\n",
        "\n",
        "        x_data = []\n",
        "        y_data = []\n",
        "        for line in csv_reader:\n",
        "            features = line[1]\n",
        "            x = [1] + [float(features)]    # x_data에 bias를 위한 1추가\n",
        "            y = float(line[0])\n",
        "\n",
        "            x_data.append(x)\n",
        "            y_data.append(y)\n",
        "\n",
        "        x_array = np.array(x_data)\n",
        "        y_array = np.array(y_data)\n",
        "\n",
        "    return header, x_array, y_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "URdRm_p4NKrw"
      },
      "outputs": [],
      "source": [
        "_, x_train, y_train = Load_Iris_Dataset('./Iris_Train.csv')\n",
        "_, x_test, y_test = Load_Iris_Dataset('./Iris_Test.csv')\n",
        "\n",
        "\n",
        "# train 데이터 시각화\n",
        "is_virginica_x = x_train[y_train == 1]\n",
        "is_virginica_y = y_train[y_train == 1]\n",
        "\n",
        "not_virginica_x = x_train[y_train == 0]\n",
        "not_virginica_y = y_train[y_train == 0]\n",
        "\n",
        "plt.scatter(is_virginica_x[:, 1], is_virginica_y, color='b', label='Iris-Virginica')\n",
        "plt.scatter(not_virginica_x[:, 1], not_virginica_y, color='r', label='Not Iris-Virginica')\n",
        "\n",
        "plt.xlabel(\"Petal width\", fontsize=14)\n",
        "plt.ylabel(\"Class\", fontsize=14)\n",
        "plt.legend(loc=\"upper left\", fontsize=10)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LS0_GPqYNKrw"
      },
      "outputs": [],
      "source": [
        "# Scikit-Learn 으로 학습\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lr = LogisticRegression()\n",
        "lr.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3DnYDQoINKrw"
      },
      "outputs": [],
      "source": [
        "# train data에 대한 학습 모델 시각화\n",
        "is_virginica_x = x_train[y_train == 1]\n",
        "is_virginica_y = y_train[y_train == 1]\n",
        "\n",
        "not_virginica_x = x_train[y_train == 0]\n",
        "not_virginica_y = y_train[y_train == 0]\n",
        "\n",
        "plot_feat = np.linspace(0, 3, 100).reshape(-1, 1)\n",
        "plot_x = np.insert(plot_feat, 0, 1, axis=1)\n",
        "plot_prob = lr.predict(plot_x)\n",
        "\n",
        "plt.scatter(is_virginica_x[:, 1], is_virginica_y, color='b', label='Iris-Virginica')\n",
        "plt.scatter(not_virginica_x[:, 1], not_virginica_y, color='r', label='Not Iris-Virginica')\n",
        "\n",
        "\n",
        "# 모델이 학습한 Probability\n",
        "plt.plot(plot_feat, plot_prob, 'g-', label='Hypothesis')\n",
        "\n",
        "plt.xlabel(\"Petal width\", fontsize=14)\n",
        "plt.ylabel(\"Probability\", fontsize=14)\n",
        "plt.legend(loc=\"upper left\", fontsize=10)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "blKGnzPDNKrw"
      },
      "outputs": [],
      "source": [
        "# 평가\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "y_pred = lr.predict(x_test)\n",
        "print('Test Accuracy: {:.2f}%'.format(accuracy_score(y_test, y_pred)*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tO9AAE58NKrx"
      },
      "source": [
        "## Numerical Solution 구현"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RC3zXuW1v-r8"
      },
      "outputs": [],
      "source": [
        "# 데이터 준비\n",
        "import os                            # 데이터 파일 경로 설정\n",
        "import csv                           # 데이터 파일 로드\n",
        "import numpy as np                   # numpy 행렬 조작\n",
        "import matplotlib.pyplot as plt      # 그래프 그리기(선택 사항)\n",
        "\n",
        "def Load_Iris_Dataset(filename):\n",
        "    with open(filename, 'r') as f:\n",
        "        csv_reader = csv.reader(f)                  # 파일 로드\n",
        "        header = next(csv_reader)\n",
        "\n",
        "        x_data = []\n",
        "        y_data = []\n",
        "        for line in csv_reader:\n",
        "            features = line[1]\n",
        "            x = [1] + [float(features)]    # x_data에 bias를 위한 1추가\n",
        "            y = float(line[0])\n",
        "\n",
        "            x_data.append(x)\n",
        "            y_data.append(y)\n",
        "\n",
        "        x_array = np.array(x_data)\n",
        "        y_array = np.array(y_data)\n",
        "\n",
        "    return header, x_array, y_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tLffsZtJv-r8"
      },
      "outputs": [],
      "source": [
        "_, x_train, y_train = Load_Iris_Dataset('./Iris_Train.csv')\n",
        "_, x_test, y_test = Load_Iris_Dataset('./Iris_Test.csv')\n",
        "\n",
        "\n",
        "# train 데이터 시각화\n",
        "is_virginica_x = x_train[y_train == 1]\n",
        "is_virginica_y = y_train[y_train == 1]\n",
        "\n",
        "not_virginica_x = x_train[y_train == 0]\n",
        "not_virginica_y = y_train[y_train == 0]\n",
        "\n",
        "plt.scatter(is_virginica_x[:, 1], is_virginica_y, color='b', label='Iris-Virginica')\n",
        "plt.scatter(not_virginica_x[:, 1], not_virginica_y, color='r', label='Not Iris-Virginica')\n",
        "\n",
        "plt.xlabel(\"Petal width\", fontsize=14)\n",
        "plt.ylabel(\"Class\", fontsize=14)\n",
        "plt.legend(loc=\"upper left\", fontsize=10)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJ7KurljjWkq"
      },
      "source": [
        "### 모델 정의\n",
        "1.   __\\_\\_init\\_\\___\n",
        "\n",
        "\n",
        "> *   인자: 모델 설정\n",
        "*   출력: x\n",
        "*   기능: 모델 초기화\n",
        "\n",
        "> weight *W*를 random하게 initialization\n",
        "\n",
        "2.   __train__\n",
        "\n",
        "\n",
        "> *   입력: 학습데이터, 학습 설정\n",
        "*   출력: Loss\n",
        "*   기능: 데이터로 모델 학습\n",
        "\n",
        "> 매 epoch마다 전체 데이터에 대해 loss, grad 계산하여 학습\n",
        "\n",
        "\n",
        "3. __predict__\n",
        "\n",
        "> *   입력: 검증 데이터\n",
        "*   출력: 모델의 예측값\n",
        "*   기능: train로 학습된 모델로 검증, 예측값 생성\n",
        "\n",
        "> 검증 데이터에 대해 분류 예측 결과 산출\n",
        "\n",
        "4. ___sigmoid__\n",
        "\n",
        "> *   입력: 실수형 numpy array\n",
        "*   출력: sigmoid를 취한 array\n",
        "*   기능: 주어진 array에 대한 모든 sigmoid 값 계산\n",
        "\n",
        "> $sigmoid(x) =\\frac{1}{ 1+e^{-(x)}}$\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "both",
        "id": "mTCU7B8tkx2S"
      },
      "outputs": [],
      "source": [
        "class LogisticRegression:\n",
        "    def __init__(self, num_features, seed):\n",
        "        np.random.seed(seed)\n",
        "        self.W = np.random.rand(num_features, 1)\n",
        "\n",
        "    def train(self, train_x, train_y, num_epochs, learning_rate):\n",
        "        loss_memory = []\n",
        "        train_y = np.expand_dims(train_y, 1)\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "          # prediction 계산 𝑿^𝑻 𝑾\n",
        "          prediction = np.matmul(train_x, self.W)\n",
        "\n",
        "          # sigmoid 적용\n",
        "          prob = self._sigmoid(prediction)\n",
        "\n",
        "          # Loss 계산\n",
        "          error = prob - train_y\n",
        "          loss = - np.mean(train_y * np.log(prob) + (1 - train_y) * np.log(1 - prob))\n",
        "\n",
        "          # Gradient 계산\n",
        "          grad = np.mean(train_x * error, axis=0, keepdims=True).T\n",
        "\n",
        "          # Weight Update\n",
        "          self.W -= grad * learning_rate\n",
        "\n",
        "          loss_memory.append(loss)\n",
        "        return loss_memory\n",
        "\n",
        "    def predict_prob(self, test_x):\n",
        "        prob = self._sigmoid(np.matmul(test_x, self.W))\n",
        "        return prob.flatten()\n",
        "\n",
        "    def predict(self, test_x):\n",
        "        prob = self._sigmoid(np.matmul(test_x, self.W))\n",
        "        prob = prob.flatten()\n",
        "        y_pred_one_or_zero = []\n",
        "        for y in prob:\n",
        "            if y > 0.5:\n",
        "                y_pred_one_or_zero.append(1)\n",
        "            else:\n",
        "                y_pred_one_or_zero.append(0)\n",
        "        return y_pred_one_or_zero\n",
        "\n",
        "    def _sigmoid(self, x):\n",
        "        return 1 / (1 + np.exp(-x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IBt5hJWkzK8g"
      },
      "outputs": [],
      "source": [
        "# Hyper-parameter 설정 및 학습\n",
        "num_epochs = 1000\n",
        "learning_rate = 1e-1\n",
        "seed = 2\n",
        "\n",
        "# Training\n",
        "num_data, num_features = x_train.shape\n",
        "\n",
        "model = LogisticRegression(num_features, seed)\n",
        "loss_memory = model.train(x_train, y_train, num_epochs, learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eB_0wtckza9D"
      },
      "outputs": [],
      "source": [
        "# Plot Loss\n",
        "x_axis = list(range(num_epochs))\n",
        "\n",
        "plt.plot(x_axis, loss_memory)\n",
        "plt.title('Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('MSE Loss')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tBqV4GWc1CzM"
      },
      "outputs": [],
      "source": [
        "# train data에 대한 학습 모델 시각화\n",
        "is_virginica_x = x_train[y_train == 1]\n",
        "is_virginica_y = y_train[y_train == 1]\n",
        "\n",
        "not_virginica_x = x_train[y_train == 0]\n",
        "not_virginica_y = y_train[y_train == 0]\n",
        "\n",
        "plot_feat = np.linspace(0, 3, 100).reshape(-1, 1)\n",
        "plot_x = np.insert(plot_feat, 0, 1, axis=1)\n",
        "plot_prob = model.predict_prob(plot_x)\n",
        "\n",
        "plt.scatter(is_virginica_x[:, 1], is_virginica_y, color='b', label='Iris-Virginica')\n",
        "plt.scatter(not_virginica_x[:, 1], not_virginica_y, color='r', label='Not Iris-Virginica')\n",
        "\n",
        "# 모델이 학습한 Probability\n",
        "plt.plot(plot_feat, plot_prob, 'g-', label='Hypothesis')\n",
        "\n",
        "plt.xlabel(\"Petal width\", fontsize=14)\n",
        "plt.ylabel(\"Probability\", fontsize=14)\n",
        "plt.legend(loc=\"upper left\", fontsize=10)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kOjimBnwAYOM"
      },
      "outputs": [],
      "source": [
        "# train data에 대한 학습 모델 시각화\n",
        "is_virginica_x = x_train[y_train == 1]\n",
        "is_virginica_y = y_train[y_train == 1]\n",
        "\n",
        "not_virginica_x = x_train[y_train == 0]\n",
        "not_virginica_y = y_train[y_train == 0]\n",
        "\n",
        "plot_feat = np.linspace(0, 3, 100).reshape(-1, 1)\n",
        "plot_x = np.insert(plot_feat, 0, 1, axis=1)\n",
        "plot_prob = model.predict(plot_x)\n",
        "\n",
        "plt.scatter(is_virginica_x[:, 1], is_virginica_y, color='b', label='Iris-Virginica')\n",
        "plt.scatter(not_virginica_x[:, 1], not_virginica_y, color='r', label='Not Iris-Virginica')\n",
        "\n",
        "# 모델이 학습한 Probability\n",
        "plt.plot(plot_feat, plot_prob, 'g-', label='Hypothesis')\n",
        "\n",
        "plt.xlabel(\"Petal width\", fontsize=14)\n",
        "plt.ylabel(\"Probability\", fontsize=14)\n",
        "plt.legend(loc=\"upper left\", fontsize=10)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-1iNKRE1Ous"
      },
      "outputs": [],
      "source": [
        "# 평가\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "y_pred = model.predict(x_test)\n",
        "print('Test Accuracy: {:.2f}%'.format(accuracy_score(y_test, y_pred)*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgEnvzmMNKry"
      },
      "source": [
        "## 스팸메일 데이터에서 SKLearn과 Numerical solution 비교\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QCGKydaicskb"
      },
      "outputs": [],
      "source": [
        "# 데이터 준비\n",
        "import os                            # 데이터 파일 경로 설정\n",
        "import csv                           # 데이터 파일 로드\n",
        "import numpy as np                   # numpy 행렬 조작\n",
        "\n",
        "def Load_Spam_Dataset(filename):\n",
        "    with open(filename, 'r') as f:\n",
        "        csv_reader = csv.reader(f)                  # 파일 로드\n",
        "        header = next(csv_reader)\n",
        "\n",
        "        x_data = []\n",
        "        y_data = []\n",
        "        for line in csv_reader:\n",
        "            features = line[:-1]\n",
        "            x = [1] + list(map(float, features))   # x_data에 bias를 위한 1추가\n",
        "            y = float(line[-1])\n",
        "\n",
        "            x_data.append(x)\n",
        "            y_data.append(y)\n",
        "\n",
        "        x_array = np.array(x_data)\n",
        "        y_array = np.array(y_data)\n",
        "\n",
        "    return header, x_array, y_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j8LMdIMVGm6R"
      },
      "outputs": [],
      "source": [
        "_, x_train, y_train = Load_Spam_Dataset('./Spam_train.csv')\n",
        "_, x_test, y_test = Load_Spam_Dataset('./Spam_test.csv')\n",
        "\n",
        "print(x_train.shape) # 데이터 수, feature 수\n",
        "print(y_train.shape) # 데이터 수"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M8g0mAwfGm6T"
      },
      "outputs": [],
      "source": [
        "# Logistic regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lr = LogisticRegression(max_iter=10000)\n",
        "lr.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ZK3WQ6xHRAR"
      },
      "outputs": [],
      "source": [
        "# 평가\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "y_pred = lr.predict(x_test)\n",
        "print('Test Accuracy: {:.2f}%'.format(accuracy_score(y_test, y_pred)*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kh3xZtanICFT"
      },
      "outputs": [],
      "source": [
        "# TODO: Numerical solution 구현 및 하이퍼파라미터 튜닝"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFTkOf31KUDv"
      },
      "source": [
        "## 유방암 데이터에서 SKLearn과 Numerical solution 비교\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pACyXa90KUDx"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "cancer = load_breast_cancer()\n",
        "print(cancer.feature_names) # feature 이름 출력\n",
        "\n",
        "# bias를 한번에 계산하기 위해, 1을 X에 추가해 줍니다.\n",
        "import numpy as np\n",
        "new_X = np.insert(cancer.data, 0, 1, axis=1)\n",
        "\n",
        "# train, test 나눔\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(new_X, cancer.target, test_size=0.3, shuffle=True, random_state=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y1Be9Ru0LE58"
      },
      "outputs": [],
      "source": [
        "# Logistic regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lr = LogisticRegression(max_iter=10000)\n",
        "lr.fit(x_train, y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MNk6ta3rKUDy"
      },
      "outputs": [],
      "source": [
        "# 평가\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "y_pred = lr.predict(x_test)\n",
        "print('Test Accuracy: {:.2f}%'.format(accuracy_score(y_test, y_pred)*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gnYw8rUBLwg0"
      },
      "outputs": [],
      "source": [
        "# TODO: Numerical solution 구현 및 하이퍼파라미터 튜닝"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2y5av-MJdZQ"
      },
      "source": [
        "# 3. Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_OubnXR2JgKp"
      },
      "outputs": [],
      "source": [
        "# 데이터 준비\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# 유방암(Breast Cancer) 환자 데이터, 569개 데이터, 30개의 feature, 환자 class 2 (음성, 양성)\n",
        "cancer = load_breast_cancer()\n",
        "\n",
        "x = cancer.data\n",
        "y = cancer.target\n",
        "print(cancer.feature_names)\n",
        "\n",
        "# train, test 나눔\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, shuffle=True, random_state=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BFNFcyJfKvih"
      },
      "outputs": [],
      "source": [
        "# 모델 학습\n",
        "depth=3\n",
        "max_leaf_nodes=10\n",
        "model = DecisionTreeClassifier(criterion='entropy', max_depth=depth, max_leaf_nodes=max_leaf_nodes, random_state=2021) # decision tree\n",
        "# model = RandomForestClassifier(criterion='entropy', max_depth=depth, max_leaf_nodes=max_leaf_nodes, random_state=2021) # random forest\n",
        "\n",
        "model.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ndme3mxK4Q3"
      },
      "outputs": [],
      "source": [
        "# 모델 평가\n",
        "pred = model.predict(x_test)\n",
        "print(\"Accuracy: %.6f\" % accuracy_score(y_true=y_test, y_pred=pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kY8sYYnbK-SS"
      },
      "outputs": [],
      "source": [
        "# 모델 분석\n",
        "\n",
        "from sklearn.tree import plot_tree, export_text\n",
        "from IPython import display\n",
        "\n",
        "feature_names = cancer.feature_names\n",
        "target_names = cancer.target_names\n",
        "\n",
        "# 시각화(텍스트)\n",
        "text_representation = export_text(model)\n",
        "print(text_representation)\n",
        "\n",
        "\n",
        "# 시각화(그림)\n",
        "plt.figure(figsize=(20,20))\n",
        "tree_plot = plot_tree(model,\n",
        "                      feature_names=feature_names,\n",
        "                      class_names = target_names,\n",
        "                      label = 'all',\n",
        "                      rounded=True,\n",
        "                      proportion = True,\n",
        "                      filled=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "heJEfFoXLitp"
      },
      "outputs": [],
      "source": [
        "#  Depth에 따른 정확도 변화\n",
        "accuracy = []\n",
        "max_depth=10\n",
        "max_leaf_nodes=10\n",
        "\n",
        "# depth 1부터 10까지\n",
        "for depth in range(1, max_depth + 1):\n",
        "    model = DecisionTreeClassifier(criterion='entropy', max_depth=depth, max_leaf_nodes=max_leaf_nodes, random_state=2021)\n",
        "    # model = RandomForestClassifier(criterion='entropy', max_depth=depth, max_leaf_nodes=max_leaf_nodes, random_state=2021)\n",
        "    model.fit(x_train, y_train)\n",
        "\n",
        "    pred = model.predict(x_test)\n",
        "\n",
        "    acc = accuracy_score(y_true=y_test, y_pred=pred)\n",
        "    accuracy.append(acc)\n",
        "\n",
        "# 시각화\n",
        "plt.plot(list(range(1, max_depth + 1)), accuracy)\n",
        "plt.xlabel('Depth')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z6wY7CzI1uaw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCMc_jRmch31"
      },
      "source": [
        "## 와인 데이터에서의 Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8STF9_W2coHm"
      },
      "outputs": [],
      "source": [
        "# 와인 데이터, 178개 데이터, 13개의 feature, 와인 종류 3가지\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "wine = load_wine()\n",
        "\n",
        "x = wine.data\n",
        "y = wine.target\n",
        "\n",
        "# train, test 나눔\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, shuffle=True, random_state=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RPQtbUFQZluK"
      },
      "outputs": [],
      "source": [
        "# Tree 기반 모델\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# 모델 튜닝\n",
        "depth=3\n",
        "max_leaf_nodes=10\n",
        "model = DecisionTreeClassifier(criterion='entropy', max_depth=depth, max_leaf_nodes=max_leaf_nodes, random_state=2021) # decision tree\n",
        "# model = RandomForestClassifier(criterion='entropy', max_depth=depth, max_leaf_nodes=max_leaf_nodes, random_state=2021) # random forest\n",
        "\n",
        "# 모델 학습\n",
        "model.fit(x_train, y_train)\n",
        "\n",
        "# 모델 평가\n",
        "pred = model.predict(x_test)\n",
        "print(\"Accuracy: %.6f\" % accuracy_score(y_true=y_test, y_pred=pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uC00WgtOcrW9"
      },
      "source": [
        "## 스팸 데이터에서의 Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CtI699W9crXC"
      },
      "outputs": [],
      "source": [
        "# 데이터 준비\n",
        "import os                            # 데이터 파일 경로 설정\n",
        "import csv                           # 데이터 파일 로드\n",
        "import numpy as np                   # numpy 행렬 조작\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def Load_Spam_Dataset(filename):\n",
        "    with open(filename, 'r') as f:\n",
        "        csv_reader = csv.reader(f)                  # 파일 로드\n",
        "        header = next(csv_reader)\n",
        "\n",
        "        x_data = []\n",
        "        y_data = []\n",
        "        for line in csv_reader:\n",
        "            features = line[:-1]\n",
        "            x = [1] + list(map(float, features))   # x_data에 bias를 위한 1추가\n",
        "            y = float(line[-1])\n",
        "\n",
        "            x_data.append(x)\n",
        "            y_data.append(y)\n",
        "\n",
        "        x_array = np.array(x_data)\n",
        "        y_array = np.array(y_data)\n",
        "\n",
        "    return header, x_array, y_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0iqcT1pLYPSL"
      },
      "outputs": [],
      "source": [
        "_, x_train, y_train = Load_Spam_Dataset('./Spam_train.csv')\n",
        "_, x_test, y_test = Load_Spam_Dataset('./Spam_test.csv')\n",
        "\n",
        "print(x_train.shape) # 데이터 수, feature 수\n",
        "print(y_train.shape) # 데이터 수"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "weafF319YWhw"
      },
      "outputs": [],
      "source": [
        "# Tree 기반 모델\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "depth=3\n",
        "max_leaf_nodes=10\n",
        "model = DecisionTreeClassifier(criterion='entropy', max_depth=depth, max_leaf_nodes=max_leaf_nodes, random_state=2021) # decision tree\n",
        "# model = RandomForestClassifier(criterion='entropy', max_depth=depth, max_leaf_nodes=max_leaf_nodes, random_state=2021) # random forest\n",
        "\n",
        "# 모델 학습\n",
        "model.fit(x_train, y_train)\n",
        "\n",
        "# 모델 평가\n",
        "pred = model.predict(x_test)\n",
        "print(\"Accuracy: %.6f\" % accuracy_score(y_true=y_test, y_pred=pred))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}