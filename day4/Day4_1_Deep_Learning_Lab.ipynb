{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0GE9PoYTyDS"
      },
      "source": [
        "# Lab 05. Deep Learning - MLP, CNN, RNN\n",
        "\n",
        "## Table of Contents\n",
        "- Perceptron & MLP\n",
        "- CNN\n",
        "- RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-kiB2TFTYH8"
      },
      "source": [
        "import os\n",
        "import copy\n",
        "from os.path import join\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-tr3WCxTlwf"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "np.random.seed(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEK2gLWsVpT6"
      },
      "source": [
        "## 1. Perceptron"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bj3-KrBjUDe0"
      },
      "source": [
        "X = np.array([[2, 2], [1, 3], [2, 3], [5, 3], [2, 4], [3, 4],\n",
        "              [6, 4], [1, 5], [5, 5], [4, 6], [6, 6], [5, 7]])\n",
        "Y = np.array([0, 0, 0, 1, 0, 0,\n",
        "              1, 0, 1, 1, 1, 1])\n",
        "\n",
        "# 위 X,Y 데이터를 점 그래프로 표현 / 라이브러리 이름 matplotlib\n",
        "plt.scatter(X[:, 0], X[:, 1], c=Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5Fu2uTWUVav"
      },
      "source": [
        "from sklearn.linear_model import Perceptron\n",
        "\n",
        "# 모델 생성\n",
        "model = Perceptron(tol=1e-3, max_iter=100)\n",
        "\n",
        "# 모델 학습\n",
        "model.fit(X, Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YN6yQGQ-UYWf"
      },
      "source": [
        "# 2차원 공간의 점들의 좌표. x와 y의 최대, 최소값을 구하여, 그래프의 가로축 세로축 길이를 결정.\n",
        "h = 0.02\n",
        "\n",
        "# horizontal은 가로축, vertical는 세로축을 의미. (그래프를 그릴 평면의 사이즈 설정)\n",
        "# X[:, 0]은 좌표 값들 중 가로축의 값.\n",
        "# X[:, 1]은 좌표 값들 중 세로축의 값.\n",
        "horizontal_min, horizontal_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
        "vertical_min, vertical_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "\n",
        "# 0.02 간격으로 min값과 max 사이 matrix를 생성하기 위한 작업.\n",
        "xx, yy = np.meshgrid(np.arange(horizontal_min, horizontal_max, h),\n",
        "                     np.arange(vertical_min, vertical_max, h))\n",
        "\n",
        "print(xx)\n",
        "print(xx.shape)\n",
        "\n",
        "print()\n",
        "print(yy)\n",
        "print(yy.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnmKw2rhUbT_"
      },
      "source": [
        "# 공간 상의 점들(영역)에 대한 모델의 예측 값들을 구함.\n",
        "# 평면에 색을 칠하기 위해 0.02 간격의 점들에 대해 모두 예측값을 구한 것.(하늘색과 주황색 평면)\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "# ravel() : 1차원으로 푸는것. == 'reshape(-1, 1).squeeze()'\n",
        "print(xx.ravel().shape)\n",
        "print()\n",
        "\n",
        "# c_[array1, array2] : column_stack  <-> row stack (r_[array1, array2])\n",
        "'''\n",
        "[1,    6]     [1, 6]\n",
        "[2, +  7]  =  [2, 7]\n",
        "[3,    8]     [3, 8]\n",
        "\n",
        "'''\n",
        "\n",
        "xxx = np.c_[xx.ravel(), yy.ravel()]\n",
        "print(xxx)\n",
        "print()\n",
        "print(xxx.shape)\n",
        "\n",
        "Z = model.predict(xxx)\n",
        "\n",
        "# 예측 값(0 or 1)에 색을 넣고 그래프에 (영역을) 그린다.\n",
        "Z = Z.reshape(xx.shape)\n",
        "ax.contourf(xx, yy, Z, cmap=plt.cm.Paired)\n",
        "ax.axis('off') # axis on/off\n",
        "\n",
        "# 본래 우리가 예측하려던 입력 데이터(점)를 그린다.\n",
        "ax.scatter(X[:, 0], X[:, 1], c=Y)\n",
        "ax.set_title('Perceptron')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUeer-Ulgsm2"
      },
      "source": [
        "## 2. MLP with XOR Problem\n",
        "\n",
        "---\n",
        "\n",
        "Perceptron은 단순한 데이터, 즉 선형 분리가 가능한 (Linearly separable)한 데이터에서는 아주 잘 동작합니다.<br>\n",
        "하지만 데이터가 선형으로 분리가 가능하지 않다면 동작하지 않습니다.\n",
        "\n",
        "대표적인 문제가 XOR Problem 입니다.<br>\n",
        "XOR는 Exclusive OR의 약자로 두 입력 중 오직 하나만이 참일 때 참, 그 외에는 거짓이 되는 연산입니다.\n",
        "\n",
        "<h2 align=\"center\">\n",
        "  <img src='https://miro.medium.com/max/300/0*LYlt6CZJHOJkNRHJ.' height=147 width=300/>\n",
        "</h2>\n",
        "\n",
        "<!-- ![XOR](https://miro.medium.com/max/300/0*LYlt6CZJHOJkNRHJ.) -->\n",
        "\n",
        "\n",
        "\n",
        "아래 두 블록의 코드를 실행해봅니다.<br>\n",
        "어떤 직선을 그어도 입력에 대해 XOR를 참과 거짓으로 분류할 수 없습니다.<br>\n",
        "\n",
        "하나의 직선 혹은 하나의 Perceptron으로 분류할 수 없다면 여러 개를 사용해서 분류할 수 있을까요?<br>\n",
        "Multilayer Perceptron (MLP)로 XOR 문제를 풀어보도록 하겠습니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJruvsf7gsm3"
      },
      "source": [
        "x = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "y = np.array([[0.0], [1.0], [1.0], [0.0]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7hmHKKygsm6"
      },
      "source": [
        "# True 인 경우 빨간 o로, False인 경우 파란 x로 그래프 표현\n",
        "XOR_TRUE = x[y[:, 0]==1, :]\n",
        "XOR_FALSE = x[y[:, 0]==0, :]\n",
        "\n",
        "# print(XOR_TRUE)\n",
        "# print(XOR_FALSE)\n",
        "\n",
        "plt.scatter(XOR_TRUE[:, 0], XOR_TRUE[:, 1], color='r', marker='o', s=300)\n",
        "plt.scatter(XOR_FALSE[:, 0], XOR_FALSE[:, 1], color='b', marker='x', s=300)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6S1-BHTgsm8"
      },
      "source": [
        "### XOR 문제 해결\n",
        "\n",
        "\n",
        "구현할 모델의 개요는 아래와 같은 MLP 입니다.\n",
        "\n",
        "<h2 align=\"left\">\n",
        "  <img src='https://miro.medium.com/max/630/1*qA_APGgbbh0QfRNsRyMaJg.png' height=250 width=400/>\n",
        "</h2>\n",
        "\n",
        "[이미지 출처: Neural Network XOR Application and Fundamentals](https://becominghuman.ai/neural-network-xor-application-and-fundamentals-6b1d539941ed)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDFvlVQpWFCI"
      },
      "source": [
        "# Scikit-learn(sklearn) 버전\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# 1 hidden layer with 2 hidden nodes\n",
        "hidden_layers = (2, )\n",
        "\n",
        "# 과연 어느 정도의 learning rate로 몇 iteration을 학습해야\n",
        "# XOR을 풀 수 있는 지 확인해보세요!\n",
        "solver = 'sgd'\n",
        "learning_rate = 1.0\n",
        "max_iter = 10\n",
        "verbose = True # 매 epoch 마다 학습 양상(loss 변화) 출력 여부\n",
        "\n",
        "# 모델 생성\n",
        "# activation='logistic' == sigmoid function\n",
        "model = MLPClassifier(hidden_layer_sizes=hidden_layers, solver=solver, activation='logistic',\n",
        "                      learning_rate_init =learning_rate, max_iter=max_iter, verbose=verbose,\n",
        "                      n_iter_no_change=1000, random_state=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObXOtQoXW9Pw",
        "scrolled": true
      },
      "source": [
        "# 모델 학습\n",
        "model.fit(x, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8dHlOVlX5CI"
      },
      "source": [
        "# 학습 결과 확인\n",
        "pred = model.predict(x)\n",
        "for i in range(len(x)):\n",
        "    print('Pred: %d, Answer: %d' % (pred[i], y[i]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwGQMhvyXUU1"
      },
      "source": [
        "W1, W2 = model.coefs_\n",
        "b1, b2 = model.intercepts_\n",
        "\n",
        "# print(W1.shape)\n",
        "# print(W2.shape)\n",
        "# print(b1.shape)\n",
        "# print(b2.shape)\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "hidden_layer = sigmoid(np.matmul(x, W1) + b1)\n",
        "output_layer = sigmoid(np.matmul(hidden_layer, W2) + b2)\n",
        "\n",
        "h1 = hidden_layer[:, 0]\n",
        "h2 = hidden_layer[:, 1]\n",
        "print('[Hidden Node Values]')\n",
        "print('Input \\t H1   H2  Pred Answer')\n",
        "print(x[0], ' ', '%.2f' % h1[0], '%.2f' % h2[0], '  %d' % pred[0], '   %d' % y[0])\n",
        "print(x[1], ' ', '%.2f' % h1[1], '%.2f' % h2[1], '  %d' % pred[1], '   %d' % y[1])\n",
        "print(x[2], ' ', '%.2f' % h1[2], '%.2f' % h2[2], '  %d' % pred[2], '   %d' % y[2])\n",
        "print(x[3], ' ', '%.2f' % h1[3], '%.2f' % h2[3], '  %d' % pred[3], '   %d' % y[3])\n",
        "\n",
        "# print(W2)\n",
        "# print(b2)\n",
        "# print(np.matmul(hidden_layer, W2))\n",
        "# print(output_layer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AydhVDA0TDQK"
      },
      "source": [
        "## 3. Convolutional Neural Network\n",
        "이미지를 분류하는 모델을 만들어 보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "keYMwmfeTIOX"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "torch.manual_seed(2021)\n",
        "torch.cuda.manual_seed(2021)\n",
        "torch.backends.cudnn.deterministic=True\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # cuda\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdkPAhpMZNXk"
      },
      "source": [
        "### 데이터셋 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbaueuyWT6p-"
      },
      "source": [
        "# Dataset 다운로드\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "# print(type(trainset))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7YhSaCsZS0q"
      },
      "source": [
        "### 이미지 몇 개만 확인해보기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSpeOXoET6ia"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# image를 출력하는 함수\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "# trainset image를 갖고 와서 image 4개를 확인해본다.\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "# print labels\n",
        "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnsvc4zSZVwd"
      },
      "source": [
        "### CNN 정의하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmJxDpQ-T6bi"
      },
      "source": [
        "# CNN 모델 정의\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "net = Net().to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRJc8tzPZXWm"
      },
      "source": [
        "### 손실함수와 optimizer 정의하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPwX-mXoT6Uv"
      },
      "source": [
        "# 손실함수와 optimizer 정의\n",
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTUqxRcHZvII"
      },
      "source": [
        "### CNN 학습하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQSDu26kT6OV"
      },
      "source": [
        "# CNN 학습\n",
        "for epoch in range(2):  # 시간 관계상 2 epochs만 학습한다.\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # data => [inputs, labels]\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "        # parameter의 gradient 초기화\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 2000))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fk4N3eLibC3T"
      },
      "source": [
        "### 모델 저장하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eO1K9LwAT6G1"
      },
      "source": [
        "PATH = './cifar_net.pth'\n",
        "torch.save(net.state_dict(), PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtGzoWrtbEOS"
      },
      "source": [
        "### Test 이미지 몇 개만 확인해보기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0bUYzEoT5sg"
      },
      "source": [
        "dataiter = iter(testloader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# print images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fl6oDkrhbJGi"
      },
      "source": [
        "### 위에 출력한 Test 이미지에 대한 예측"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3qy2vrwUHdm"
      },
      "source": [
        "net = Net()\n",
        "net.load_state_dict(torch.load(PATH))\n",
        "\n",
        "outputs = net(images)\n",
        "_, predicted = torch.max(outputs, 1)\n",
        "\n",
        "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
        "                              for j in range(4)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SP4iU1wbYFm"
      },
      "source": [
        "### 전체 test 데이터에 대해 accuracy 계산"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95i04cpwUHWQ"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7JFQez4bdr8"
      },
      "source": [
        "### Class 별 모델 평가"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Em6Rh3C6UN-X"
      },
      "source": [
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        c = (predicted == labels).squeeze()\n",
        "        for i in range(4):\n",
        "            label = labels[i]\n",
        "            class_correct[label] += c[i].item()\n",
        "            class_total[label] += 1\n",
        "\n",
        "for i in range(10):\n",
        "    print('Accuracy of %5s : %2d %%' % (\n",
        "        classes[i], 100 * class_correct[i] / class_total[i]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUYYEpZO7izB"
      },
      "source": [
        "### Fashion-MNIST로 CNN을 모델링하기\n",
        "**None 부분을 채워주세요! <br>**\n",
        "> 첫 번째 / 두 번째 conv. layer 출력 채널 수: 5개, 10개 <br>\n",
        "Conv. layer의 kernel 크기: 5 X 5 <br>\n",
        "Hint: Fashion-MNIST는 흑백 이미지라서 채널 수가 1개 <br>\n",
        "사용할 함수: nn.Conv2d(), nn.Linear(), view()\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9S7MX_b7cNI"
      },
      "source": [
        "class FashionNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        self.conv1 = None\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = None\n",
        "        self.fc1 = None\n",
        "        self.fc2 = nn.Linear(120, 60)\n",
        "        self.fc3 = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = None\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 정답코드\n",
        "\n",
        "class FashionNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FashionNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 5, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(5, 10, 5)\n",
        "        self.fc1 = nn.Linear(10 * 4 * 4, 120)\n",
        "        self.fc2 = nn.Linear(120, 60)\n",
        "        self.fc3 = nn.Linear(60, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 10 * 4 * 4)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "cellView": "form",
        "id": "1JtS6HNF_L0_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋 불러오기\n",
        "trainset = torchvision.datasets.FashionMNIST(\"./data\", download=True,\n",
        "                                              transform=transforms.Compose([transforms.ToTensor()]))\n",
        "testset = torchvision.datasets.FashionMNIST(\"./data\", download=True, train=False,\n",
        "                                             transform=transforms.Compose([transforms.ToTensor()]))\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('T-shirt/Top', 'Trouser', 'Pullover', 'Dress',\n",
        "           'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')\n",
        "\n",
        "print(next(iter(trainloader))[0].shape)"
      ],
      "metadata": {
        "id": "_eDpX39d6ztB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지 몇 개만 확인해보기\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# image를 출력하는 함수\n",
        "def imshow(img):\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "# trainset image를 갖고 와서 image 4개를 확인해본다.\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "# print labels\n",
        "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
      ],
      "metadata": {
        "id": "xE0Je3ll7Ri2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 정의하기\n",
        "net = FashionNet().to(device)"
      ],
      "metadata": {
        "id": "4wbhNglZ7oKm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 손실함수와 optimizer 정의\n",
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ],
      "metadata": {
        "id": "younTiZn73Av"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 학습하기\n",
        "# CNN 학습\n",
        "for epoch in range(2):  # 시간 관계상 2 epochs만 학습한다.\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # data => [inputs, labels]\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "        # parameter의 gradient 초기화\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 2000))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "id": "ypBXQLCU8NYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 테스트 이미지 몇 개만 확인해보기\n",
        "dataiter = iter(testloader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# print images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))"
      ],
      "metadata": {
        "id": "Q-mf4NQT8R8m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 저장하기\n",
        "PATH = './fasion_net.pth'\n",
        "torch.save(net.state_dict(), PATH)"
      ],
      "metadata": {
        "id": "4mUTilM2_NSk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 불러오기\n",
        "net = FashionNet()\n",
        "net.load_state_dict(torch.load(PATH))"
      ],
      "metadata": {
        "id": "HD6_Kcku_PMa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 위의 이미지에 대한 예측\n",
        "outputs = net(images)\n",
        "_, predicted = torch.max(outputs, 1)\n",
        "\n",
        "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
        "                              for j in range(4)))"
      ],
      "metadata": {
        "id": "X3hEIr-Y-ply"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 전체 테스트 데이터에 대해 정확도 계산\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))"
      ],
      "metadata": {
        "id": "HEf7BO-d-upP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 클래스 별 모델 평가\n",
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        c = (predicted == labels).squeeze()\n",
        "        for i in range(4):\n",
        "            label = labels[i]\n",
        "            class_correct[label] += c[i].item()\n",
        "            class_total[label] += 1\n",
        "\n",
        "for i in range(10):\n",
        "    print('Accuracy of %5s : %2d %%' % (\n",
        "        classes[i], 100 * class_correct[i] / class_total[i]))"
      ],
      "metadata": {
        "id": "cXSoqfug-6GG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7OKMDRFr_hi2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}